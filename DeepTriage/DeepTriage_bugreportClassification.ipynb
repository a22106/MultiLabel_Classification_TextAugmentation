{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import json, re, nltk, string\n",
    "from nltk.corpus import wordnet\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Input, merge\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_bugs_json = 'D:\\\\BugTriage\\\\Chrome\\\\deep_data.json'\n",
    "closed_bugs_json = 'D:\\\\BugTriage\\\\Chrome\\\\classifier_data_0.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Word2vec parameters\n",
    "min_word_frequency_word2vec = 5\n",
    "embed_size_word2vec = 200\n",
    "context_window_word2vec = 5\n",
    "\n",
    "#2. Classifier hyperparameters\n",
    "numCV = 10\n",
    "max_sentence_len = 50\n",
    "min_sentence_length = 15\n",
    "rankK = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(open_bugs_json) as data_file:\n",
    "    data = json.load(data_file, strict=False)\n",
    "\n",
    "all_data = []\n",
    "for item in data:\n",
    "    #1. Remove \\r \n",
    "    current_title = item['issue_title'].replace('\\r', ' ')\n",
    "    current_desc = item['description'].replace('\\r', ' ')    \n",
    "    #2. Remove URLs\n",
    "    current_desc = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', current_desc)    \n",
    "    #3. Remove Stack Trace\n",
    "    start_loc = current_desc.find(\"Stack trace:\")\n",
    "    current_desc = current_desc[:start_loc]    \n",
    "    #4. Remove hex code\n",
    "    current_desc = re.sub(r'(\\w+)0x\\w+', '', current_desc)\n",
    "    current_title= re.sub(r'(\\w+)0x\\w+', '', current_title)    \n",
    "    #5. Change to lower case\n",
    "    current_desc = current_desc.lower()\n",
    "    current_title = current_title.lower()    \n",
    "    #6. Tokenize\n",
    "    current_desc_tokens = nltk.word_tokenize(current_desc)\n",
    "    current_title_tokens = nltk.word_tokenize(current_title)\n",
    "    #7. Strip trailing punctuation marks    \n",
    "    current_desc_filter = [word.strip(string.punctuation) for word in current_desc_tokens]\n",
    "    current_title_filter = [word.strip(string.punctuation) for word in current_title_tokens]      \n",
    "    #8. Join the lists\n",
    "    current_data = current_title_filter + current_desc_filter\n",
    "    current_data = filter(None, current_data)\n",
    "    all_data.append(current_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_model = Word2Vec(all_data, min_count=min_word_frequency_word2vec, size=embed_size_word2vec, window=context_window_word2vec)\n",
    "vocabulary = wordvec_model.vocab\n",
    "vocab_size = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}